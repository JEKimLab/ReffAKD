{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5523bc-ba2e-4452-9d45-b9e2243c005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f7980-1458-41c7-a1e7-617f79b147fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models, datasets\n",
    "from random import randint\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734914a-7a98-40bc-ba7a-d17b360a5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e469eee-8c17-41fd-8f99-e2fc38e50464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = datasets.FashionMNIST('./', train=True, download=True)\n",
    "\n",
    "# Stick all the images together to form a 600000 X 28 array\n",
    "x = np.concatenate([np.asarray(train_data[i][0]) for i in range(len(train_data))])\n",
    "\n",
    "# calculate the mean and std along the (0, 1) axes\n",
    "mean = np.mean(x, axis=(0, 1))/255\n",
    "std = np.std(x, axis=(0, 1))/255\n",
    "# the the mean and std\n",
    "mean=mean.tolist()\n",
    "std=std.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7393549e-51b2-49cc-b06d-6b47ec789a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mean = {mean}, std = {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3195d-9e83-4310-a442-43546b4f72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def show_batch(dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = next(dataiter)    \n",
    "    imshow(make_grid(images)) # Using Torchvision.utils make_grid function\n",
    "    \n",
    "def show_image(dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = next(dataiter)\n",
    "    random_num = randint(0, len(images)-1)\n",
    "    imshow(images[random_num])\n",
    "    label = labels[random_num]\n",
    "    print(f'Label: {label}, Shape: {images[random_num].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d14429-d32f-4ced-835d-fdf95194a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation - optional depending on future resnet implementation\n",
    "\n",
    "# Define transformation sequence for image pre-processing\n",
    "# If not using pre-trained model, normalize with 0.5, 0.5, 0.5 (mean and SD)\n",
    "# If using pre-trained ImageNet, normalize with mean=[0.485, 0.456, 0.406], \n",
    "# std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((32,32)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(15),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "                # T.Resize(256), # Resize images to 256 x 256\n",
    "                # T.CenterCrop(224), # Center crop image\n",
    "                # T.RandomHorizontalFlip(),\n",
    "                T.Resize((32,32)),\n",
    "                T.ToTensor(),  # Converting cropped images to tensors\n",
    "                T.Normalize(mean, std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e7079-9408-41df-8e28-07b38929299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c5666-7683-48df-876f-af8d53d76b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FashionMNIST(\"./\",\n",
    "                                         train=True,\n",
    "                                         download=True,\n",
    "                                         transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size, shuffle=True, num_workers=2,pin_memory=True)\n",
    "\n",
    "testset = datasets.FashionMNIST(\"./\",\n",
    "                                        train=False,\n",
    "                                        download=True,\n",
    "                                        transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size*2,pin_memory=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796779ed-d900-4b9b-a9af-0fedb8801d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27319a-3489-4953-a602-2c84eca3b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "def test():\n",
    "    net = LeNet5(10)\n",
    "    y = net(torch.randn(1, 1, 32, 32))\n",
    "    print(y.size())\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6ec25-c671-414a-bd0f-168042238cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e83a6-bdcb-4b38-9c4a-8678f4fecf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': test_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train': len(train_loader.dataset),\n",
    "    'val': len(test_loader.dataset),\n",
    "    'test': len(test_loader.dataset),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed402649-6ec9-4cae-b89c-a3f4ed0101af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_kd(outputs, labels, teacher_outputs, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! See Issue #2\n",
    "    \"\"\"\n",
    "    teacher_outputs = teacher_outputs.double()\n",
    "    alpha = kwargs['alpha']\n",
    "    T = kwargs['temperature']\n",
    "\n",
    "    loss_CE = F.cross_entropy(outputs, labels)\n",
    "    D_KL = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1), teacher_outputs) * (T * T)\n",
    "    KD_loss =  (1. - alpha)*loss_CE + alpha*D_KL\n",
    "\n",
    "    return KD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335cd94-b798-4417-a007-80aaee73bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_probabilities = torch.tensor(torch.load('./tiny_ae_fashion_mnist.pt'))\n",
    "soft_probabilities = F.softmax(torch.tensor(soft_probabilities), dim = 1)\n",
    "print(soft_probabilities.shape)\n",
    "print(soft_probabilities.type())\n",
    "soft_probabilities = soft_probabilities.to(device)\n",
    "print(soft_probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0c4fd-c513-4b20-8e12-a3d58f7a8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soft_probabilities.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a5cc5-0c73-4349-9481-c9f5cc5936ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_kd(\n",
    "    torch.randn(128,200),\n",
    "    torch.randn(128,200),\n",
    "    F.softmax(torch.randn(128,200), dim=1),\n",
    "    alpha = 0.65,\n",
    "    temperature = 1\n",
    "    # {'alpha': 0.65, 'temperature': 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd0724-95d8-4c63-9693-beaa0a2b0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_model(model, criterion_kd, optimizer, scheduler, alpha, num_epochs=25, temp=1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                teacher_outputs = soft_probabilities[labels]\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    outputs = outputs.double()\n",
    "                    # print(outputs.type())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion_kd(outputs, labels, teacher_outputs, alpha=alpha, temperature=temp)\n",
    "                    # print(loss.type())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print('Saving..')\n",
    "                state = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'acc': epoch_acc,\n",
    "                    'epoch': epoch,\n",
    "                }\n",
    "                # if not os.path.isdir('checkpoint'):\n",
    "                #     os.mkdir('checkpoint')\n",
    "                torch.save(state, './lenet_distilled_tiny_ae.pth')\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff7fb0-c264-4bc1-a5d5-a3ec7f072760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def accuracyAtk(output, target, topk=(1,5)):\n",
    "    \"\"\"\n",
    "    Computes the accuracy over the k top predictions for the specified values of k\n",
    "    In top-5 accuracy you give yourself credit for having the right answer\n",
    "    if the right answer appears in your top five guesses.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = (pred == target.unsqueeze(dim=0)).expand_as(pred)\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k)\n",
    "        return res\n",
    "\n",
    "def eval_model(model):\n",
    "    since = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    final_top_1, final_top_5 = 0,0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            top1, top5 = accuracyAtk(outputs, labels)\n",
    "            final_top_1 += top1\n",
    "            final_top_5 += top5\n",
    "    \n",
    "    top1_acc = final_top_1/dataset_sizes['test']\n",
    "    top5_acc = final_top_5/dataset_sizes['test']\n",
    "    print(f'Top 1 test accuracy = {top1_acc}, Top 5 test accuract = {top5_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ac8f4-c149-4992-9f91-c4750c26113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "for t in [20, 10, 5, 1]:\n",
    "    for i in range(1, 10, 1):\n",
    "        model_ft = LeNet5(num_classes=10)\n",
    "        model_ft = model_ft.to(device)\n",
    "\n",
    "        criterion = loss_fn_kd\n",
    "        optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "        exp_lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer_ft, milestones=[60, 120, 160], gamma=0.2)\n",
    "        model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, i/10, num_epochs=200, temp=t)\n",
    "        eval_model(model_ft)\n",
    "        del model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124688b8-fab3-4afc-99d8-f425b1cc454a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
